# Metrica Vox Machina
> **Gold Standard Computational Linguistics Evaluation for AI**

**Note**: While the system is confirmed to meet 100% of focus-group led requirements, it was time and scope limited as 26,000+ words had to be simultaeneously authored for the accompanying thesis, crucial for the fulfillment of the Master of Science (Computer Science) degree schema.

For university submission and mark tracing purposes, the code has been condensed into a single file. Originally, the project's `tkinter` functionality and package-based logic spanned across 20+ files. A comprehensive, web-based version of Metrica Vox Machina is slated for release. The full project code will be uploaded after mark ratification.

ğŸŒ **Location**: Birmingham, UK  
ğŸ› **Institution**: University of Birmingham  
ğŸ“… **Duration**: May 2023 - Sep 2023

## ğŸ“Œ Overview
The recent surge in the adoption of large language models, especially post-GPT-3, underscores the need for standardized, user-friendly evaluation tools. "Metrica Vox Machina" rises to this challenge, offering a suite of evaluative tools designed to rigorously assess the performance of these language models across varied chat-based domains and functionalities.

## ğŸ“ƒ Abstract
The modern landscape of language models, each with its unique specializations, demands a robust evaluative system with a standardized approach. This study dives deep into the creation and utility of "Metrica Vox Machina", including:
- **Bidirectional Machine Translation**: Supporting 50 languages.
- **Human Evaluation Tool**: With JSON-validating dataset management.
- **Contextual Embedding Tool**: Enhanced with CUDA core threading and data validation.

Continuous evaluations indicate that the system adeptly meets its design objectives.

## ğŸ— Keywords
`Machine Translation` `Metrics` `Human Evaluation` `Contextual Embedding` `Large Language Models` `AI` `Benchmarking` `Natural Language Processing` `Computational Linguistics` `AGILE` `Confidence Interval` `Focus Group` `User-Friendly` `Decision Making` `Precision` `Recall` `F1` `QA` `Python`.

## ğŸ† Achievements
- ğŸ’» Authored **3000+ lines** of Python code, integrating **41+ libraries**.
- ğŸŒ Developed a **50-language bi-directional Machine Translation system** optimized with BLEU, ROUGE, METEOR, and BERT.
- ğŸ® Leveraged gamification techniques, resulting in a **500% surge** in user-initiated data entries.
- ğŸ”„ Conducted **10 AGILE testing phases** with 42 focus group participants, meeting **100%** of **90+ requirements**.

## ğŸ™ Acknowledgements
Gratitude to:
- **Dr. Jizheng Wan**, my project supervisor, for his astute career guidance and willingness to enable free exploration into the NLP domain. Further projects are planned in NLP thanks to his general stewardship.
- **Dr. Rajesh Chitnis**, my project inspector, for allocating his time to receive the demonstration and emphasising rigorous documentation to "do justice" (in terms of academic awardings) to the project.
- The **43 focus group members** whose contributions were instrumental in refining the system within the limited 10 weeks for implementation.

---
