# Metrica Vox Machina
> **Gold Standard Computational Linguistics Evaluation for AI**

**Note**: While the system is confirmed to meet 100% of focus-group led requirements, it was time and scope limited as 26,000+ words had to be simultaeneously authored for the accompanying thesis, crucial for the fulfillment of the Master of Science (Computer Science) degree requirements.

For university submission and mark tracing purposes, the code has been condensed into a single file. Originally, the project's `tkinter` functionality and package-based logic spanned across 20+ files. A comprehensive, web-based version of Metrica Vox Machina is slated for release. The full project code will be uploaded after mark ratification in November 2023.

ğŸŒ **Location**: Birmingham, UK  
ğŸ› **Institution**: University of Birmingham  
ğŸ“… **Duration**: May 2022 - Sep 2023

## ğŸ“Œ Overview
The recent surge in the adoption of large language models, especially post-GPT-3, underscores the need for standardized, user-friendly evaluation tools. "Metrica Vox Machina" rises to this challenge, offering a suite of evaluative tools designed to rigorously assess the performance of these language models across varied chat-based domains and functionalities.

## ğŸ“ƒ Abstract
The modern landscape of language models, each with its unique specializations, demands a robust evaluative system with a standardized approach. This study dives deep into the creation and utility of "Metrica Vox Machina", including:
- **Bidirectional Machine Translation**: Supporting 50 languages.
- **Human Evaluation Tool**: With JSON-validating dataset management.
- **Contextual Embedding Tool**: Enhanced with CUDA core threading and data validation.

Continuous evaluations indicate that the system adeptly meets its design objectives.

## ğŸ— Keywords
`Machine Translation` `Metrics` `Human Evaluation` `Contextual Embedding` `Large Language Models` `AI` `Benchmarking` `Natural Language Processing` `Computational Linguistics` `AGILE` `Confidence Interval` `Focus Group` `User-Friendly` `Decision Making` `Precision` `Recall` `F1` `QA` `Python`.

## ğŸ† Achievements
- ğŸ’» Authored **3000+ lines** of Python code, integrating **41+ libraries**.
- ğŸŒ Developed a **50-language bi-directional Machine Translation system** optimized with BLEU, ROUGE, METEOR, and BERT.
- ğŸ® Leveraged gamification techniques, resulting in a **500% surge** in user-initiated data entries.
- ğŸ”„ Conducted **10 AGILE testing phases** with 42 focus group participants, meeting **100%** of **90+ requirements**.

## ğŸ™ Acknowledgements
Gratitude to:
- **Dr. Jizheng Wan**, my project supervisor, for his astute career guidance, willingness to enable free exploration into NLP and general mentorship.
- **Dr. Rajesh Chitnis**, my project inspector, for taking his time to receive the demonstration and emphasising rigorous documentation to "do justice", in terms of academic awardings, to the project.
- The **43 focus group members** whose contributions were instrumental in refining the system within the limited 10 weeks for implementation.

---
