# Metrica Vox Machina
> Gold Standard Computational Linguistics Evaluation for AI

Full release of Metrica Vox Machina will be in web-based form. Project code to be uploaded after mark ratification (Nov, 2023).

Note: This code has been simplified into a single file for mark tracing reasons (and university submission limitations). Originally, all tkinter functionality was separated from package-based logic across 20+ files.

ğŸŒ **Location**: Birmingham, UK  
ğŸ› **Institution**: University of Birmingham  
ğŸ“… **Duration**: May 2022 - Sep 2023

## ğŸ“Œ Overview
The recent surge in the adoption of large language models, especially post-GPT-3, underscores the need for standardized, user-friendly evaluation tools. "Metrica Vox Machina" rises to this challenge, offering a suite of evaluative tools designed to rigorously assess the performance of these language models across varied domains and functionalities.

## ğŸ“ƒ Abstract
The modern landscape of language models, each with its unique specializations, demands a robust evaluative system with a standardized approach. This study dives deep into the creation and utility of "Metrica Vox Machina", including:
- **Bidirectional Machine Translation**: Supporting 50 languages.
- **Human Evaluation Tool**: With JSON-validating dataset management.
- **Contextual Embedding Tool**: Enhanced with CUDA core threading and data validation.

Continuous evaluations indicate that the system adeptly meets its design objectives.

## ğŸ— Keywords
`Machine Translation` `Metrics` `Human Evaluation` `Contextual Embedding` `Large Language Models` `AI` `Benchmarking` `Natural Language Processing` `Computational Linguistics` `AGILE` `Confidence Interval` `Focus Group` `User-Friendly` `Decision Making` `Precision` `Recall` `F1` `QA` `Python`.

## ğŸ† Achievements
- ğŸ’» Authored **3000+ lines** of Python code, integrating **41+ libraries**.
- ğŸŒ Developed a **50-language bi-directional Machine Translation system** optimized with BLEU, ROUGE, METEOR, and BERT.
- ğŸ® Leveraged gamification techniques, resulting in a **500% surge** in user-initiated data entries.
- ğŸ”„ Conducted **10 AGILE testing phases** with 42 focus group participants, meeting **100%** of **90+ requirements**.

## ğŸ™ Acknowledgements
Gratitude to:
- **Dr. Jizheng Wan** for his invaluable guidance and mentorship.
- **Dr. Rajesh Chitnis** for his insights and emphasis on rigorous documentation.
- The **43 focus group members** whose contributions were instrumental in refining the system within the limited 10 weeks for implementation.

---
